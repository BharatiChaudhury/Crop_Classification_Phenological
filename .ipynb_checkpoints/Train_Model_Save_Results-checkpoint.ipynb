{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8c76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a71f2288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "#tf.config.experimental.set_memory_growth(physical_devices, True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fdacf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhara\\AppData\\Local\\Temp/ipykernel_8460/3596669406.py:12: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n",
      "  raster_array = xr.open_rasterio(os.path.join(path+\"\\\\No_Geo\",img))\n"
     ]
    }
   ],
   "source": [
    "p = \"E:\\\\Crop_Classification_Phenological\\\\UAS Precision NCAT files\"\n",
    "crop_type = [\"corn\", \"cotton\", \"soybean\"]\n",
    "crop_growth_stage = [\"2020-06-30_HSI_Sorted\", \"2020-07-23_HSI_Sorted\", \"2020-09-04_HSI_Sorted\"]\n",
    "training_hs = []\n",
    "def create_training_data():\n",
    "    for cg in crop_growth_stage:\n",
    "        class_1 = crop_growth_stage.index(cg)\n",
    "        for ct in crop_type:\n",
    "            path = os.path.join(p,cg,ct)\n",
    "            class_2 = crop_type.index(ct)\n",
    "            for img in os.listdir(path+\"\\\\No_Geo\"):\n",
    "                raster_array = xr.open_rasterio(os.path.join(path+\"\\\\No_Geo\",img))\n",
    "                data = raster_array.values\n",
    "                #print(data.shape)\n",
    "                training_hs.append([data, class_1,class_2])\n",
    "                \n",
    "create_training_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a60ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y_1=[]\n",
    "y_2=[]\n",
    "for features, label1, label2 in training_hs:\n",
    "    x,y,z = features.shape\n",
    "    if x==270:\n",
    "        #print(features[:,0:33,0:39].shape)\n",
    "        X.append(features[:,0:33,0:39])\n",
    "        y_1.append(label1)\n",
    "        y_2.append(label2)\n",
    "X= np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc749077",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,270,33*39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ee1878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779, 270, 1287)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf6068eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Nov 07 00:31:47 2021\n",
    "\n",
    "@author: bharathi\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Input, Concatenate,SpatialDropout1D\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "from keras.layers import Activation, Lambda\n",
    "\n",
    "def channel_normalization(x):\n",
    "    max_values = K.max(K.abs(x), 2, keepdims=True) + 1e-5\n",
    "    out = x / max_values\n",
    "    return out\n",
    "\n",
    "\n",
    "def wave_net_activation(x):\n",
    "    tanh_out = Activation('tanh')(x)\n",
    "    sigm_out = Activation('sigmoid')(x)\n",
    "    return tf. keras.layers.multiply([tanh_out, sigm_out])\n",
    "\n",
    "\n",
    "def residual_block(x, s, i, activation, nb_filters, kernel_size, padding, dropout_rate=0, name=''):\n",
    "\n",
    "\n",
    "    original_x = x\n",
    "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size,\n",
    "                  dilation_rate=i, padding=padding,\n",
    "                  name=name + '_dilated_conv_%d_tanh_s%d' % (i, s))(x)\n",
    "    if activation == 'norm_relu':\n",
    "        x = Activation('relu')(conv)\n",
    "        x = Lambda(channel_normalization)(x)\n",
    "    elif activation == 'wavenet':\n",
    "        x = wave_net_activation(conv)\n",
    "    else:\n",
    "        x = Activation(activation)(conv)\n",
    "\n",
    "    x = SpatialDropout1D(dropout_rate, name=name + '_spatial_dropout1d_%d_s%d_%f' % (i, s, dropout_rate))(x)\n",
    "\n",
    "    # 1x1 conv.\n",
    "    x = Conv1D(nb_filters, 1, padding='same')(x)\n",
    "    res_x = tf.keras.layers.add([original_x, x])\n",
    "    return res_x, x\n",
    "\n",
    "\n",
    "def process_dilations(dilations):\n",
    "    def is_power_of_two(num):\n",
    "        return num != 0 and ((num & (num - 1)) == 0)\n",
    "\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        # print(f'Updated dilations from {dilations} to {new_dilations} because of backwards compatibility.')\n",
    "        return new_dilations\n",
    "\n",
    "\n",
    "class TCN:\n",
    "\n",
    "    def __init__(self,\n",
    "                 nb_filters=64,\n",
    "                 kernel_size=2,\n",
    "                 nb_stacks=1,\n",
    "                 dilations=None,\n",
    "                 activation='norm_relu',\n",
    "                 padding='causal',\n",
    "                 use_skip_connections=True,\n",
    "                 dropout_rate=0.0,\n",
    "                 return_sequences=True,\n",
    "                 name='tcn'):\n",
    "        self.name = name\n",
    "        self.return_sequences = return_sequences\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.activation = activation\n",
    "        self.dilations = dilations\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "        self.padding = padding\n",
    "\n",
    "        if padding != 'causal' and padding != 'same':\n",
    "            raise ValueError(\"Only 'causal' or 'same' paddings are compatible for this layer.\")\n",
    "\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        if self.dilations is None:\n",
    "            self.dilations = [1, 2, 4, 8, 16, 32]\n",
    "        x = inputs\n",
    "        x = Conv1D(self.nb_filters, 1, padding=self.padding, name=self.name + '_initial_conv')(x)\n",
    "        skip_connections = []\n",
    "        for s in range(self.nb_stacks):\n",
    "            for i in self.dilations:\n",
    "                x, skip_out = residual_block(x, s, i, self.activation, self.nb_filters,\n",
    "                                             self.kernel_size, self.padding, self.dropout_rate, name=self.name)\n",
    "                skip_connections.append(skip_out)\n",
    "        if self.use_skip_connections:\n",
    "            x = tf.keras.layers.add(skip_connections)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        if not self.return_sequences:\n",
    "            output_slice_index = -1\n",
    "            x = Lambda(lambda tt: tt[:, output_slice_index, :])(x)\n",
    "        return x\n",
    "def model(input_shape1):\n",
    "    input1 = Input(input_shape1)\n",
    "    s1 = Conv1D(64, 270, activation ='relu', input_shape = input_shape1[1:])(input1)\n",
    "    s2 = Conv1D(64, 270, activation = 'relu', padding = 'same')(s1)\n",
    "    s3 = Conv1D(64, 270, activation = 'relu', padding = 'same')(s2)\n",
    "    #s4 = Conv1D(64, 270, activation = 'relu', padding = 'same')(s3)\n",
    "    #res_x = tf.keras.layers.add([s1, s3])\n",
    "    #x = Activation('relu')(res_x)\n",
    "\n",
    "    \n",
    "    ## Temporal Convolution Modeling\n",
    "    x = TCN(128,dilations = [1, 2, 4, 8, 16, 32], return_sequences=True, activation = 'wavenet',name = 'tnc1')(s3)\n",
    "    x = TCN(64,dilations = [1, 2, 4, 8, 16, 32], return_sequences=True, activation = 'wavenet',name = 'tnc2')(x)\n",
    "    \n",
    "    z = Flatten()(x)\n",
    "    y1 = Dense(256, activation= 'relu')(z)\n",
    "    y1 = Dense(3, activation = 'softmax',name=\"crop_growth_stage\",activity_regularizer=regularizers.l2(0.001))(y1)\n",
    "    \n",
    "    y2 = Dense(256,activation = 'relu')(z)\n",
    "    y2 = Dense(3, activation = 'softmax',name=\"crop_type\",activity_regularizer=regularizers.l2(0.001))(y2)\n",
    "    model = Model(inputs=input1, outputs=[y1,y2], name=\"temp_cnn\")\n",
    "    #model = Model(inputs=input1, outputs = y1, name='temp_cnn')\n",
    "    return model\n",
    "#model = model((270,1287))\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddd9d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = {'crop_growth_stage':'categorical_crossentropy', 'crop_type':'categorical_crossentropy'}\n",
    "metric_list = {'crop_growth_stage':'accuracy', 'crop_type':'accuracy'}\n",
    "loss_weights = {'crop_growth_stage':1.0,'crop_type':1.0}\n",
    "#loss_list = {'crop_type':'categorical_crossentropy'}\n",
    "#metric_list = {'crop_type':'accuracy'}\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2efa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............\n",
      "Training for fold1...\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.1735 - crop_growth_stage_loss: 0.0138 - crop_type_loss: 0.1578 - crop_growth_stage_accuracy: 0.9936 - crop_type_accuracy: 0.9423\n",
      ".............\n",
      "Training for fold2...\n",
      "Epoch 00028: early stopping\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2297 - crop_growth_stage_loss: 0.0592 - crop_type_loss: 0.1687 - crop_growth_stage_accuracy: 0.9679 - crop_type_accuracy: 0.9359\n",
      ".............\n",
      "Training for fold3...\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2519 - crop_growth_stage_loss: 7.4958e-04 - crop_type_loss: 0.2493 - crop_growth_stage_accuracy: 1.0000 - crop_type_accuracy: 0.8526\n",
      ".............\n",
      "Training for fold4...\n",
      "Epoch 00046: early stopping\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.4556 - crop_growth_stage_loss: 0.0465 - crop_type_loss: 0.4073 - crop_growth_stage_accuracy: 0.9936 - crop_type_accuracy: 0.8654\n",
      ".............\n",
      "Training for fold5...\n"
     ]
    }
   ],
   "source": [
    "#MT-TCN\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "from numba import cuda\n",
    "import gc\n",
    "fold_no = 1\n",
    "#Y = [y_1, y_2]\n",
    "acc1_per_fold = []\n",
    "acc2_per_fold =[]\n",
    "loss1_per_fold =[]\n",
    "loss2_per_fold =[]\n",
    "precision1 =[]\n",
    "precision2 =[]\n",
    "recall1,recall2=[],[]\n",
    "fscore1,fscore2=[],[]\n",
    "k1_coef, k2_coef = [],[]\n",
    "\n",
    "nSamples = 779\n",
    "kfold = StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "ID_Inp = np.array(range(nSamples))\n",
    "#ID_Out = np.array(range(nSamples),3)\n",
    "y_1 = np.array(y_1)\n",
    "y_2 = np.array(y_2)\n",
    "for IDs_Train, IDs_Test in kfold.split(ID_Inp, y_1):\n",
    "    x_train = X[IDs_Train]\n",
    "    \n",
    "    y_train_1, y_train_2 = y_1[IDs_Train], y_2[IDs_Train]\n",
    "    \n",
    "    y_train_1 = np_utils.to_categorical(y_train_1,3)\n",
    "    y_train_2 = np_utils.to_categorical(y_train_2,3)\n",
    "    \n",
    "    x_test = X[IDs_Test]\n",
    "    y_test_1, y_test_2 = y_1[IDs_Test], y_2[IDs_Test]\n",
    "    \n",
    "    y_test_1 = np_utils.to_categorical(y_test_1,3)\n",
    "    y_test_2 = np_utils.to_categorical(y_test_2,3)\n",
    "    \n",
    "    neural_network = model((270,1287))\n",
    "    tf.random.set_seed(1234)\n",
    "\n",
    "    neural_network.compile(optimizer = opt, loss=loss_list, metrics=metric_list,loss_weights = loss_weights)\n",
    "    \n",
    "    print('.............')\n",
    "    print(f'Training for fold{fold_no}...')\n",
    "    \n",
    "    model_history = neural_network.fit(x_train,[y_train_1,y_train_2],batch_size=32,epochs = 50,validation_data = (x_test,[y_test_1,y_test_2]),callbacks=[es],verbose=0)\n",
    "    \n",
    "    scores = neural_network.evaluate(x_test,[y_test_1,y_test_2])\n",
    "    \n",
    "    results = neural_network.predict(x_test)\n",
    "    #print(results)\n",
    "    \n",
    "    prediction_cg = results[0]\n",
    "    prediction_ct = results[1]\n",
    "\n",
    "    pr_cg = prediction_cg\n",
    "    pr_ct = prediction_ct\n",
    "\n",
    "    labels_cg = np.argmax(pr_cg, axis=1)\n",
    "    labels_ct = np.argmax(pr_ct, axis=1)\n",
    "\n",
    "    y_t1 = np.argmax(y_test_1, axis=1)\n",
    "    y_t2 = np.argmax(y_test_2, axis=1)\n",
    "\n",
    "\n",
    "    \n",
    "    precision, recall, fscore, support = score(labels_ct, y_t1)\n",
    "    kappa_coefficient_ct = cohen_kappa_score(labels_ct, y_t1)\n",
    "    \n",
    "    precision1.append(precision)\n",
    "    recall1.append(recall)\n",
    "    fscore1.append(fscore)\n",
    "    k1_coef.append(kappa_coefficient_ct)\n",
    "\n",
    "    precision, recall, fscore, support = score(labels_cg, y_t2)\n",
    "    kappa_coefficient_cg = cohen_kappa_score(labels_cg, y_t2)\n",
    "    \n",
    "    precision2.append(precision)\n",
    "    recall2.append(recall)\n",
    "    fscore2.append(fscore)\n",
    "    k2_coef.append(kappa_coefficient_cg)\n",
    "    \n",
    "    acc1_per_fold.append(scores[3])\n",
    "    acc2_per_fold.append(scores[4])\n",
    "    \n",
    "    loss1_per_fold.append(scores[1])\n",
    "    loss2_per_fold.append(scores[2])\n",
    "    \n",
    "    fold_no += 1\n",
    "    del scores,results, x_train,y_train_1,y_train_2,x_test,y_test_1,y_test_2\n",
    "    gc.collect()\n",
    "    \n",
    "#==provide average scores==\n",
    "print('........')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc1_per_fold)):\n",
    "    print('.......')\n",
    "    print(f'>fold {i+1} - loss{loss1_per_fold[i]}- Accuracy:{acc1_per_fold[i]}%')\n",
    "    print(f'>fold {i+1} - loss{loss2_per_fold[i]}- Accuracy:{acc2_per_fold[i]}%')\n",
    "    \n",
    "print('.......')\n",
    "print('Average scores for all folds:')\n",
    "print(f'>Crop Growth Stage Accuracy:{np.mean(acc1_per_fold)}(+-{np.std(acc1_per_fold)})')\n",
    "print(f'>Crop Type Accuracy:{np.mean(acc2_per_fold)}(+-{np.std(acc2_per_fold)})')\n",
    "\n",
    "\n",
    "print(f'>Loss:{np.mean(loss1_per_fold)}')\n",
    "print(f'>Loss:{np.mean(loss1_per_fold)}')\n",
    "      \n",
    "print('.......')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54c929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
